{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ウナギ\n",
    "\n",
    "この Notebook は、プログラミングの例題として実施しています。\n",
    "この分析結果は、AI によって生成されたもので **不正確である可能性があります** 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォントの設定（グラフ表示用）\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'MS Gothic']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# データの読み込み\n",
    "data_url = \"https://www.jfa.maff.go.jp/j/saibai/attach/xls/unagi-17.xlsx\"\n",
    "response = requests.get(data_url)\n",
    "excel_data = BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excelファイルの内容を確認\n",
    "xls = pd.ExcelFile(excel_data)\n",
    "print(\"シート名一覧:\")\n",
    "print(xls.sheet_names)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 各シートの内容をプレビュー\n",
    "for sheet_name in xls.sheet_names:\n",
    "    print(f\"シート: {sheet_name}\")\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    print(df.head())\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# データのクリーニングと整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "df = pd.read_excel(excel_data, sheet_name='ウナギ稚魚採捕量', header=None)\n",
    "df.drop(index=df.index[[0,1]],\n",
    "        columns=df.columns[[0, 3]], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.rename(columns={1: 'Japanese Era', 2: 'ammount'}, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "JERA_SHIFT = {\n",
    "    'S': 1925, # 昭和元年 1926\n",
    "    'H': 1988, # 平成元年 1989\n",
    "    'R': 2018, # 令和元年 2019\n",
    "}\n",
    "\n",
    "jera_pattern = re.compile(r'([A-Z])(元|\\d+)')\n",
    "def jera2year(text):\n",
    "    m = jera_pattern.match(text)\n",
    "    if m is None:\n",
    "        logging.warning(text)\n",
    "        return 0\n",
    "    jera =  m.group(1)\n",
    "    jyear = m.group(2)\n",
    "    if jyear == '元':\n",
    "        jyear = 1\n",
    "    return int(JERA_SHIFT[jera] + int(jyear))\n",
    "\n",
    "df['year'] = df['Japanese Era'].map(jera2year)\n",
    "\n",
    "# year列とammount列を数値型に変換\n",
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['ammount'] = pd.to_numeric(df['ammount'], errors='coerce')\n",
    "\n",
    "df.dropna(subset=['ammount'], inplace=True)\n",
    "\n",
    "df.set_index('Japanese Era', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォントの設定（グラフ表示用）\n",
    "plt.rcParams['font.sans-serif'] = ['YuGothic', 'Noto Sans JP', 'Noto Sans JP']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 図のサイズを設定\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# ========================================\n",
    "# グラフ1: 全期間の時系列推移\n",
    "# ========================================\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df['year'], df['ammount'], \n",
    "         marker='o', linewidth=2, markersize=4, color='#2E86AB')\n",
    "ax1.set_xlabel('年度', fontsize=12)\n",
    "ax1.set_ylabel('採捕量（トン）', fontsize=12)\n",
    "ax1.set_title('ニホンウナギ（シラスウナギ）採捕量の推移 (1957-2021)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(df['year'].min()-2, df['year'].max()+2)\n",
    "\n",
    "# ピーク年をハイライト\n",
    "peak_idx = df['ammount'].idxmax()\n",
    "peak_year = df.loc[peak_idx, 'year']\n",
    "peak_amount = df.loc[peak_idx, 'ammount']\n",
    "ax1.scatter(peak_year, peak_amount, color='red', s=200, zorder=5, alpha=0.6)\n",
    "ax1.annotate(f'ピーク: {peak_year}年\\n{peak_amount}トン',\n",
    "             xy=(peak_year, peak_amount),\n",
    "             xytext=(peak_year+5, peak_amount+20),\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "# ========================================\n",
    "# グラフ2: 10年移動平均とトレンド\n",
    "# ========================================\n",
    "ax2 = axes[1]\n",
    "\n",
    "# 元データ\n",
    "ax2.plot(df['year'], df['ammount'], \n",
    "         marker='o', linewidth=1, markersize=3, alpha=0.5, \n",
    "         color='gray', label='実測値')\n",
    "\n",
    "# 10年移動平均\n",
    "df['移動平均'] = df['ammount'].rolling(window=10, center=True).mean()\n",
    "ax2.plot(df['year'], df['移動平均'], \n",
    "         linewidth=3, color='#A23B72', label='10年移動平均')\n",
    "\n",
    "# トレンドライン（線形回帰）\n",
    "z = np.polyfit(df['year'], df['ammount'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax2.plot(df['year'], p(df['year']), \n",
    "         '--', linewidth=2, color='#F18F01', label='トレンドライン')\n",
    "\n",
    "ax2.set_xlabel('年度', fontsize=12)\n",
    "ax2.set_ylabel('採捕量（トン）', fontsize=12)\n",
    "ax2.set_title('トレンド分析（10年移動平均）', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='upper right', fontsize=10)\n",
    "ax2.set_xlim(df['year'].min()-2, df['year'].max()+2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "min_idx = df['ammount'].idxmin()  # インデックス位置を取得\n",
    "min_year = df.loc[min_idx, 'year']\n",
    "min_amount = df.loc[min_idx, 'ammount']\n",
    "\n",
    "# ========================================\n",
    "# 基本統計の表示\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"データサマリー\")\n",
    "print(\"=\"*60)\n",
    "print(f\"データ期間: {df['year'].min()}年 〜 {df['year'].max()}年\")\n",
    "print(f\"ピーク: {peak_year}年 ({peak_amount}トン)\")\n",
    "print(f\"最小値: {df['year'].iloc[df['ammount'].idxmin()]}年 ({df['ammount'].min()}トン)\")\n",
    "print(f\"平均採捕量: {df['ammount'].mean():.1f}トン\")\n",
    "print(f\"直近10年平均: {df.tail(10)['ammount'].mean():.1f}トン\")\n",
    "print(f\"減少率（ピークから直近）: {((df['ammount'].iloc[-1] - peak_amount) / peak_amount * 100):.1f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 利用可能な日本語フォントを検索\n",
    "japanese_fonts = [f.name for f in fm.fontManager.ttflist if 'JP' in f.name or 'Japanese' in f.name or 'Gothic' in f.name or 'Mincho' in f.name]\n",
    "print(\"利用可能な日本語フォント:\")\n",
    "print(japanese_fonts[:10])  # 最初の10個を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Cohere で分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "load_dotenv()\n",
    "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
    "\n",
    "# ========================================\n",
    "# データをテキスト形式で準備\n",
    "# ========================================\n",
    "def prepare_data_summary(df):\n",
    "    \"\"\"データフレームを分析用のテキストに変換\"\"\"\n",
    "    \n",
    "    # 基本統計\n",
    "    peak_idx = df['ammount'].idxmax()\n",
    "    min_idx = df['ammount'].idxmin()\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "ニホンウナギ（シラスウナギ）採捕量データの概要：\n",
    "\n",
    "【データ期間】{int(df['year'].min())}年 〜 {int(df['year'].max())}年（{len(df)}年分のデータ）\n",
    "\n",
    "【主要統計】\n",
    "- ピーク: {int(df.loc[peak_idx, 'year'])}年 ({df.loc[peak_idx, 'ammount']}トン)\n",
    "- 最小値: {int(df.loc[min_idx, 'year'])}年 ({df.loc[min_idx, 'ammount']}トン)\n",
    "- 平均採捕量: {df['ammount'].mean():.1f}トン\n",
    "- 最近10年平均: {df.tail(10)['ammount'].mean():.1f}トン\n",
    "- 減少率（ピークから最新）: {((df['ammount'].iloc[-1] - df.loc[peak_idx, 'ammount']) / df.loc[peak_idx, 'ammount'] * 100):.1f}%\n",
    "\n",
    "【年代別データサンプル】\n",
    "1950-1960年代: {df[df['year'] < 1970]['ammount'].mean():.1f}トン（平均）\n",
    "1970-1980年代: {df[(df['year'] >= 1970) & (df['year'] < 1990)]['ammount'].mean():.1f}トン（平均）\n",
    "1990-2000年代: {df[(df['year'] >= 1990) & (df['year'] < 2010)]['ammount'].mean():.1f}トン（平均）\n",
    "2010-2020年代: {df[df['year'] >= 2010]['ammount'].mean():.1f}トン（平均）\n",
    "\n",
    "【最近5年のデータ】\n",
    "\"\"\"\n",
    "    for _, row in df.tail(5).iterrows():\n",
    "        summary += f\"{int(row['year'])}年: {row['ammount']}トン\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "data_summary = prepare_data_summary(df)\n",
    "print(data_summary)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# Cohereによる分析実行\n",
    "# ========================================\n",
    "def analyze_with_cohere(data_text, analysis_type=\"general\"):\n",
    "    \"\"\"Cohereを使ってデータ分析を実行\"\"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"general\": f\"\"\"以下のニホンウナギ（シラスウナギ）採捕量データを分析してください。\n",
    "\n",
    "{data_text}\n",
    "\n",
    "以下の観点から分析を行ってください：\n",
    "1. 長期的なトレンドの特徴\n",
    "2. 顕著な変化が見られる時期とその背景要因\n",
    "3. 現在の状況の深刻さ\n",
    "4. データから読み取れる懸念点\n",
    "\n",
    "専門的かつ分かりやすく説明してください。\"\"\",\n",
    "        \n",
    "        \"causes\": f\"\"\"以下のニホンウナギ採捕量データの減少要因について分析してください。\n",
    "\n",
    "{data_text}\n",
    "\n",
    "以下の観点から考察してください：\n",
    "1. 生態学的要因（産卵場所、回遊ルート、気候変動など）\n",
    "2. 人為的要因（乱獲、河川環境の変化、海洋汚染など）\n",
    "3. 社会経済的要因（需要の変化、漁業規制など）\n",
    "\n",
    "各要因の相対的な重要性も含めて説明してください。\"\"\",\n",
    "        \n",
    "        \"forecast\": f\"\"\"以下のニホンウナギ採捕量データに基づいて、今後の予測と提言を行ってください。\n",
    "\n",
    "{data_text}\n",
    "\n",
    "以下について考察してください：\n",
    "1. 現在のトレンドが続いた場合の5年後、10年後の予測\n",
    "2. 資源回復に必要な対策\n",
    "3. 持続可能な管理のための提言\n",
    "\n",
    "科学的根拠に基づいた実現可能な提案をお願いします。\"\"\"\n",
    "    }\n",
    "    \n",
    "    prompt = prompts.get(analysis_type, prompts[\"general\"])\n",
    "    \n",
    "    response = co.chat(\n",
    "        message=prompt,\n",
    "        model=\"command-a-03-2025\",\n",
    "        temperature=0.3,\n",
    "        # stream=True  # ストリーミングを有効にする場合\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# ========================================\n",
    "# 分析1: 総合的なトレンド分析\n",
    "# ========================================\n",
    "print(\"【分析1: 総合的なトレンド分析】\")\n",
    "print(\"=\"*60)\n",
    "analysis_general = analyze_with_cohere(data_summary, \"general\")\n",
    "print(analysis_general)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# RAG で補正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 知識ベースの準備\n",
    "# ========================================\n",
    "# ニホンウナギに関する外部知識 ※修正予定\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"title\": \"ニホンウナギの生態\",\n",
    "        \"content\": \"ニホンウナギ（Anguilla japonica）は、マリアナ諸島西方海域で産卵し、シラスウナギとして日本、中国、台湾、韓国などの河川に遡上する。産卵場所の特定は2006年に塚本勝巳博士らによって行われた。回遊距離は約3000kmに及ぶ。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"絶滅危惧種指定\",\n",
    "        \"content\": \"2014年6月、国際自然保護連合（IUCN）のレッドリストで絶滅危惧IB類に指定された。日本国内でも2013年に環境省レッドリストで絶滅危惧IB類に指定されている。主な減少要因は乱獲、生息地の減少、海洋環境の変化などが挙げられる。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"漁業規制の動向\",\n",
    "        \"content\": \"2014年から池入れ数量の上限設定が開始された。養鰻業者による池入れ制限は、日本、中国、台湾、韓国の4カ国・地域で合意された。日本の池入れ上限は約21.7トンに設定されている。しかし、違法漁獲や密輸の問題も指摘されている。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"気候変動の影響\",\n",
    "        \"content\": \"黒潮の流路変動や海水温の上昇がシラスウナギの輸送効率に影響を与えている可能性が指摘されている。エルニーニョ現象との関連性も研究されており、海洋環境の変化が漁獲量の変動に大きく影響していると考えられる。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"河川環境の変化\",\n",
    "        \"content\": \"河川の護岸工事、ダム建設、水質汚染などにより、ウナギの生息環境が悪化している。特に、河口域の改変や中流域の連続性の分断が、ウナギの生活史に悪影響を及ぼしている。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"完全養殖の研究\",\n",
    "        \"content\": \"2010年に水産総合研究センターが世界で初めてニホンウナギの完全養殖に成功。しかし、コストや生存率の問題から商業化には至っていない。完全養殖の実用化には、まだ技術的・経済的課題が多く残されている。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"歴史的な漁獲量の変遷\",\n",
    "        \"content\": \"1960年代には年間200トン前後の豊漁が続いていたが、1970年代後半から減少傾向が顕著になった。特に2000年代以降は急激な減少が続き、2013年には過去最低の5.2トンを記録した。\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"国際的な取引規制\",\n",
    "        \"content\": \"ワシントン条約（CITES）での規制対象化が議論されているが、まだ附属書への掲載には至っていない。東アジア各国での消費需要が高く、規制強化には国際協調が不可欠である。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# テキストの埋め込み生成\n",
    "# ========================================\n",
    "def create_embeddings(texts):\n",
    "    \"\"\"テキストリストの埋め込みを生成\"\"\"\n",
    "    response = co.embed(\n",
    "        texts=texts,\n",
    "        model=\"embed-multilingual-v3.0\",  # 多言語対応モデル\n",
    "        input_type=\"search_document\"\n",
    "    )\n",
    "    return response.embeddings\n",
    "\n",
    "# 知識ベースの埋め込みを生成\n",
    "knowledge_texts = [f\"{doc['title']}: {doc['content']}\" for doc in knowledge_base]\n",
    "knowledge_embeddings = create_embeddings(knowledge_texts)\n",
    "\n",
    "print(\"知識ベースの埋め込みを生成しました\")\n",
    "print(f\"ドキュメント数: {len(knowledge_embeddings)}\")\n",
    "print(f\"埋め込みの次元数: {len(knowledge_embeddings[0])}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 類似度検索とRerank\n",
    "# ========================================\n",
    "def retrieve_relevant_docs(query, top_k=3):\n",
    "    \"\"\"クエリに関連するドキュメントを検索\"\"\"\n",
    "    \n",
    "    # クエリの埋め込みを生成\n",
    "    query_embedding = co.embed(\n",
    "        texts=[query],\n",
    "        model=\"embed-multilingual-v3.0\",\n",
    "        input_type=\"search_query\"\n",
    "    ).embeddings[0]\n",
    "    \n",
    "    # コサイン類似度を計算\n",
    "    similarities = []\n",
    "    for i, doc_embedding in enumerate(knowledge_embeddings):\n",
    "        similarity = np.dot(query_embedding, doc_embedding) / (\n",
    "            np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
    "        )\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # 類似度順にソート\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    initial_results = similarities[:top_k*2]  # Rerankのために多めに取得\n",
    "    \n",
    "    # Rerankで精度向上\n",
    "    rerank_docs = [knowledge_texts[i] for i, _ in initial_results]\n",
    "    rerank_response = co.rerank(\n",
    "        query=query,\n",
    "        documents=rerank_docs,\n",
    "        model=\"rerank-multilingual-v3.0\",\n",
    "        top_n=top_k\n",
    "    )\n",
    "    \n",
    "    # Rerank結果から関連ドキュメントを取得\n",
    "    relevant_docs = []\n",
    "    for result in rerank_response.results:\n",
    "        original_idx = initial_results[result.index][0]\n",
    "        relevant_docs.append({\n",
    "            \"content\": knowledge_base[original_idx],\n",
    "            \"relevance_score\": result.relevance_score\n",
    "        })\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "# ========================================\n",
    "# RAG分析の実行\n",
    "# ========================================\n",
    "def rag_analysis(data_summary, analysis_query):\n",
    "    \"\"\"RAGを使用した分析\"\"\"\n",
    "    \n",
    "    print(f\"クエリ: {analysis_query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 関連ドキュメントを取得\n",
    "    relevant_docs = retrieve_relevant_docs(analysis_query, top_k=3)\n",
    "    \n",
    "    print(\"【取得された関連知識】\")\n",
    "    for i, doc in enumerate(relevant_docs, 1):\n",
    "        print(f\"\\n{i}. {doc['content']['title']} (関連度: {doc['relevance_score']:.3f})\")\n",
    "        print(f\"   {doc['content']['content']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # RAGプロンプトの構築\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"【参考情報{i}】{doc['content']['title']}\\n{doc['content']['content']}\"\n",
    "        for i, doc in enumerate(relevant_docs, 1)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"以下の参考情報とデータを基に、ニホンウナギの漁獲量について分析してください。\n",
    "\n",
    "{context}\n",
    "\n",
    "【漁獲量データ】\n",
    "{data_summary}\n",
    "\n",
    "【分析テーマ】\n",
    "{analysis_query}\n",
    "\n",
    "参考情報を活用しながら、データのトレンドを科学的・客観的に分析してください。\n",
    "具体的な数値や時期を示しながら説明してください。\"\"\"\n",
    "    \n",
    "    # Cohereで回答生成\n",
    "    response = co.chat(\n",
    "        message=prompt,\n",
    "        model=\"command-a-03-2025\",\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    \n",
    "    print(\"【RAG分析結果】\")\n",
    "    print(response.text)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# ========================================\n",
    "# 分析クエリの実行\n",
    "# ========================================\n",
    "\n",
    "# 分析1: 減少トレンドの要因分析\n",
    "print(\"\\n【RAG分析1: 漁獲量減少の要因】\\n\")\n",
    "query1 = \"1960年代から現在までのニホンウナギ漁獲量の減少トレンドについて、その主要な要因を分析してください\"\n",
    "result1 = rag_analysis(data_summary, query1)\n",
    "\n",
    "# 分析2: 2000年代以降の急激な減少\n",
    "print(\"\\n【RAG分析2: 2000年代以降の急激な減少】\\n\")\n",
    "query2 = \"2000年代以降の漁獲量の急激な減少について、生態学的・社会的背景を含めて説明してください\"\n",
    "result2 = rag_analysis(data_summary, query2)\n",
    "\n",
    "# 分析3: 今後の見通しと対策\n",
    "print(\"\\n【RAG分析3: 今後の見通しと保護対策】\\n\")\n",
    "query3 = \"現在のデータトレンドと保護策の効果を踏まえて、今後の見通しと必要な対策を提言してください\"\n",
    "result3 = rag_analysis(data_summary, query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "※この分析結果は、 **AI によって生成されたもので 不正確である可能性があります** ※"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
